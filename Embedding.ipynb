{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2916a1-8efe-4d91-b59f-13eaa9c40849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time \n",
    "from tqdm.notebook import trange, tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a3449e-bfe9-4deb-b95f-ef28b7bc4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab0b51e-5177-4b75-a564-b38dedb791b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = set(df.id.unique())\n",
    "observations = (\n",
    "    df\n",
    "    .pipe(\n",
    "        lambda x: x.assign(\n",
    "            refs=x.references.map(lambda x: [x for x in x if x in unique_ids])\n",
    "        )\n",
    "    )\n",
    "    .apply(\n",
    "        lambda x:\n",
    "           [(int(x['id']), e) for e in x['refs']]\n",
    "           if ~np.isnan(x['refs']).any() and len(x['refs']) > 0\n",
    "           else float('nan'),\n",
    "        axis=1\n",
    "    )\n",
    "    .pipe(lambda x: x[~x.isna()])\n",
    "    .pipe(lambda x: np.concatenate(x.values))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1b30dd-d6c5-4a63-8e6d-d4de654cfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations = torch.tensor(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c93670-c60e-47d4-9479-823231459c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(observations, 'data/articles.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98b223dc-633f-4a43-aae6-6ded8063751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = torch.load('data/articles.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f9ab658-448d-42bc-84ba-9993cbd70c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = observations[:, 0]\n",
    "t1 = observations[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1d9d0-332e-4db8-b24f-13733bc82b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cb9b48-a148-4c05-902f-bcd4433a47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_unique(t):\n",
    "    unique = {e: i for i, e in enumerate(t.unique().sort()[0].numpy())}\n",
    "    t = t.clone()\n",
    "    t.apply_(lambda x: unique[x])\n",
    "    return t, unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b182c116-36f1-4979-9977-7726f47d8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, transform = transform_unique(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5703f78-420e-40af-a9c8-7b7163bddabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save((X, transform), 'data/articles_prepared.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "edf06fc0-b7e3-4d12-b52b-348a93920445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b3399ae-e416-49c1-acf2-9d9884bdf76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677023266"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35affa42-f108-4958-aa3c-a74aac5b162b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94f7abe5-6cc8-4c57-8a37-711f6855206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'001677023284'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{round(time.time()):012d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbe37423-cfb3-48ad-b883-de571f9ccbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "742251f0-4b82-44da-9fb0-90856e9791f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31478])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(100000, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e21996-d695-45fc-b258-c59063483eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94bb363e-a7b1-4798-a8b4-a72921e97ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, transform = torch.load('data/articles_prepared.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6619ced7-fdc1-401b-9025-967ec6f35954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000023'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{23:06d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f25d33-0546-40a6-8dc6-865d59732a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8fe2c80-5ec2-4182-9b35-a317b566248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMatrix(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, ls, rs, vs):\n",
    "        self.ls = ls \n",
    "        self.rs = rs\n",
    "        self.vs  = vs\n",
    "        self.len = vs.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ls[idx], self.rs[idx], self.vs[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len \n",
    "    \n",
    "class NegativeSampler(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, ls, rs, vs):\n",
    "        self.unique_ls, self.counts_ls = ls.unique(return_counts=True)\n",
    "        self.unique_rs, self.counts_rs = rs.unique(return_counts=True)\n",
    "        self.unique_vs, self.counts_vs = vs.unique(return_counts=True)\n",
    "        self.len = vs.shape[0]\n",
    "        self.p_ls = self.counts_ls/self.len\n",
    "        self.p_rs = self.counts_rs/self.len\n",
    "        self.p_vs = self.counts_vs/self.len\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        l = torch.multinomial(self.p_ls, 1)[0]\n",
    "        r = torch.multinomial(self.p_rs, 1)[0]\n",
    "        v = torch.multinomial(self.p_vs, 1)[0]\n",
    "        return l, r, v\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "class NegativeSampler(torch.utils.data.Dataset):\n",
    "    def __init__(self, ls, rs, vs):\n",
    "        self.ls = ls\n",
    "        self.rs = rs\n",
    "        self.vs = vs\n",
    "        self.len = vs.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ls[idx], self.rs[idx], self.vs[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len \n",
    "    \n",
    "    def resample(self):\n",
    "        self.ls = self.ls[torch.randperm(self.ls.shape[0])]\n",
    "        self.rs = self.rs[torch.randperm(self.rs.shape[0])]\n",
    "        self.vs = self.vs[torch.randperm(self.vs.shape[0])]\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e88d02-f5bd-45bc-9a1c-6b4b1ae9758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingWithBias(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n, embedding_dim):\n",
    "        super(EmbeddingWithBias, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim \n",
    "        self.shape = (n, embedding_dim)\n",
    "        self.W = torch.nn.Embedding(n, embedding_dim)\n",
    "        self.b = torch.nn.Embedding(n, 1)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        return self.W(idx), self.b(idx)\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n, m, embedding_dim): \n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.shape = (n, m, embedding_dim)\n",
    "        self.L = EmbeddingWithBias(n, embedding_dim)\n",
    "        self.R = EmbeddingWithBias(m, embedding_dim)\n",
    "        \n",
    "    def forward(self, ls, rs):\n",
    "        \n",
    "        LW, Lb = self.L(ls)\n",
    "        RW, Rb = self.R(rs)\n",
    "        \n",
    "        return (LW * RW).sum(1) + Lb + Rb\n",
    "    \n",
    "class SymmetricMatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n, embedding_dim):\n",
    "        super(SymmetricMatrixFactorization, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.shape = (n, embedding_dim)\n",
    "        self.embeddings = EmbeddingWithBias(n, embedding_dim)\n",
    "        \n",
    "    def forward(self, ls, rs):\n",
    "        LW, Lb = self.embeddings(ls)\n",
    "        RW, Rb = self.embeddings(rs)\n",
    "        \n",
    "        # LW, RW, Lb, Rb = LW.to('cuda'), RW.to('cuda'), Lb.to('cuda'), Rb.to('cuda')\n",
    "        \n",
    "        return (LW * RW).sum(1) + Lb + Rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6ca97-6faf-42f5-b595-9a926ef87269",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124c24c0-7dae-40cf-aa77-9a036bf53002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n, dim, seed=26122022):\n",
    "    torch.manual_seed(seed)\n",
    "    m = SymmetricMatrixFactorization(n, dim)\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=0.0001)\n",
    "    losses = {\n",
    "        'train': {\n",
    "            'pos' : [],\n",
    "            'neg' : []\n",
    "        },\n",
    "        'valid': {\n",
    "            'pos' : [], \n",
    "            'neg' : []\n",
    "        }\n",
    "    }\n",
    "    return m, opt, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21929c2a-aa0a-4739-9c6c-521fcf39a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(X, batch_size, lengths, seed=27122022):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    ds_pos = SparseMatrix(X[:,0], X[:,1], torch.ones(X.shape[0]))\n",
    "    ds_train_pos, ds_valid_pos, ds__test_pos = torch.utils.data.random_split(ds_pos, lengths)\n",
    "    \n",
    "    ds_neg = NegativeSampler(X[:,0], X[:,1], torch.zeros(X.shape[0]))\n",
    "    ds_train_neg, ds_valid_neg, ds__test_neg = torch.utils.data.random_split(ds_neg, lengths)\n",
    "    \n",
    "    ds_train = torch.utils.data.ConcatDataset([ds_train_pos, ds_train_neg])\n",
    "    ds_valid = torch.utils.data.ConcatDataset([ds_valid_pos, ds_valid_neg])\n",
    "    ds__test = torch.utils.data.ConcatDataset([ds__test_pos, ds__test_neg])\n",
    "    \n",
    "    dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=True) \n",
    "    dl_valid = torch.utils.data.DataLoader(ds_valid, batch_size=batch_size, shuffle=True, drop_last=True) \n",
    "    dl__test = torch.utils.data.DataLoader(ds__test, batch_size=batch_size, shuffle=False, drop_last=False) \n",
    "    \n",
    "    return dl_train, dl_valid, dl__test, ds_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67913be7-9c0e-4cd9-9518-68478f53e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(m, opt, dl_train, dl_valid, losses, EPOCHS=1, seed=26012023):\n",
    "    \n",
    "    L_train_pos_prev = 0\n",
    "    L_train_neg_prev = 0\n",
    "    L_valid_pos_prev = 0\n",
    "    L_valid_neg_prev = 0\n",
    "    \n",
    "    print(f\" {'itr': >6} {'ech': >6} {'cur': >6} {'tp': >6} {'vp': >6} {'tn': >6} {'vn': >6} \")\n",
    "    \n",
    "    for epoch in (pbar := trange(EPOCHS)):\n",
    "        \n",
    "        L_train_pos = 0\n",
    "        L_train_neg = 0\n",
    "        L_valid_pos = 0\n",
    "        L_valid_neg = 0\n",
    "        \n",
    "        for iteration, (ls, rs, vs) in enumerate(dl_train):\n",
    "            \n",
    "            # ls = ls.to('cuda')\n",
    "            # rs = rs.to('cuda')\n",
    "            # vs = vs.to('cuda')\n",
    "            \n",
    "            vs = vs == 1\n",
    "            \n",
    "            opt.zero_grad()\n",
    "\n",
    "            p = m(ls, rs).sigmoid()\n",
    "            \n",
    "            L_pos = -(0.001+p[vs]).log().mean()\n",
    "            L_neg = -(1.001-p[~vs]).log().mean()\n",
    "            L = L_pos + L_neg\n",
    "\n",
    "            L.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            L_train_pos += L_pos.item() \n",
    "            L_train_neg += L_neg.item() \n",
    "            \n",
    "            pbar.set_description(f\" {iteration: 6d} {epoch: 6d} {L.item():.03f} {L_train_pos_prev:.03f} {L_valid_pos_prev:.03f} {L_train_neg_prev:.03f} {L_valid_neg_prev:.03f} \")\n",
    "            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for ls, rs, vs in dl_valid:\n",
    "                # ls = ls.to('cuda')\n",
    "                # rs = rs.to('cuda')\n",
    "                # vs = vs.to('cuda')\n",
    "                p = m(ls, rs).sigmoid()\n",
    "                L_pos = -(0.001 + p[ vs]).log().mean()\n",
    "                L_neg = -(1.001 - p[~vs]).log().mean()\n",
    "                L_valid_pos += L_pos.item()\n",
    "                L_valid_neg += L_neg.item()\n",
    "        \n",
    "        L_train_pos_prev = L_train_pos/len(dl_train)\n",
    "        L_train_neg_prev = L_train_neg/len(dl_train)\n",
    "        L_valid_pos_prev = L_valid_pos/len(dl_valid)\n",
    "        L_valid_neg_prev = L_valid_neg/len(dl_valid)\n",
    "        \n",
    "        losses['train']['pos'].append(L_train_pos_prev)\n",
    "        losses['train']['neg'].append(L_train_neg_prev)\n",
    "        losses['valid']['pos'].append(L_valid_pos_prev)\n",
    "        losses['valid']['neg'].append(L_valid_neg_prev)\n",
    "        \n",
    "        pbar.set_description(f\" {L_train_pos_prev:.03f} {L_valid_pos_prev:.03f} {L_train_neg_prev:.03f} {L_valid_neg_prev:.03f} \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6830740e-aa72-4b88-830e-ca26568c032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(m, dl_test):\n",
    "    L_test_pos = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ls, rs, vs in dl_valid:\n",
    "            # ls = ls.to('cuda')\n",
    "            # rs = rs.to('cuda')ii\n",
    "            # vs = vs.to('cuda')\n",
    "            p = m(ls, rs).sigmoid()\n",
    "            L_pos = -p[vs].log().mean()\n",
    "            L_neg = -(1-p[~vs]).log().mean()\n",
    "            L_test_pos += L_pos.item()\n",
    "            L_test_neg += L_neg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c4765a-9698-439a-abc4-c46081ee8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_valid, dl_test, ds_neg = prepare_dataloaders(X, 64, [0.9, 0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe6aa9c-48f0-4376-a29d-bcdbb109f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER_UNIQUE = X.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de3eca81-3018-441b-98a6-7dadb6d8460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, opt, losses = create_model(NUMBER_UNIQUE, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdcb397d-912b-4f03-a41b-02f45de41cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    itr    ech    cur     tp     vp     tn     vn \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a326611a4449b4b2eebe6b6d7be219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7f42f2c94430>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bodo/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 261, in __iter__\n",
      "    yield obj\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 34\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(m, opt, dl_train, dl_valid, losses, EPOCHS, seed)\u001b[0m\n\u001b[1;32m     31\u001b[0m L \u001b[38;5;241m=\u001b[39m L_pos \u001b[38;5;241m+\u001b[39m L_neg\n\u001b[1;32m     33\u001b[0m L\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m L_train_pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m L_pos\u001b[38;5;241m.\u001b[39mitem() \n\u001b[1;32m     37\u001b[0m L_train_neg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m L_neg\u001b[38;5;241m.\u001b[39mitem() \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(m, opt, dl_train, dl_valid, losses, EPOCHS=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e46f02-d345-4186-968d-37c37dc5906f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
